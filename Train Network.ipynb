{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loaders.data_loader import DataLoader\n",
    "from models.builder import create_memory_network\n",
    "from models.config import MemoryNetworkConfig, load_recent_weights, save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 30\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = MemoryNetworkConfig()\n",
    "config.vocab_size = 1500\n",
    "config.embedding_size = 50\n",
    "config.dropout_rate = 0.3\n",
    "config.n_lstm_nodes = 64\n",
    "config.story_max_length = 500\n",
    "config.query_max_length = 500\n",
    "config.answer_max_length = 500 # seq2seq models\n",
    "config.n_decoder_lstm = 3\n",
    "config.n_encoder_lstm = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "d_name = \"sample_conversation\"\n",
    "loader = DataLoader(d_name)\n",
    "train_data, test_data = loader.get_vectorized_data(config)\n",
    "train_stories, train_queries, train_answers = train_data\n",
    "test_stories, test_queries, test_answers = test_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_network = create_memory_network(config)\n",
    "memory_network.load_weights(f\"weights/{d_name}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "41/41 [==============================] - 44s 895ms/step - loss: 1.6485 - accuracy: 0.0281 - val_loss: 1.9610 - val_accuracy: 0.0322\n",
      "Epoch 2/30\n",
      "41/41 [==============================] - 34s 839ms/step - loss: 1.5963 - accuracy: 0.0367 - val_loss: 1.9553 - val_accuracy: 0.0332\n",
      "Epoch 3/30\n",
      "41/41 [==============================] - 34s 819ms/step - loss: 1.5404 - accuracy: 0.0374 - val_loss: 2.0045 - val_accuracy: 0.0338\n",
      "Epoch 4/30\n",
      "41/41 [==============================] - 34s 826ms/step - loss: 1.5784 - accuracy: 0.0367 - val_loss: 1.9652 - val_accuracy: 0.0337\n",
      "Epoch 5/30\n",
      "41/41 [==============================] - 34s 842ms/step - loss: 1.5391 - accuracy: 0.0367 - val_loss: 2.0265 - val_accuracy: 0.0191\n",
      "Epoch 6/30\n",
      "41/41 [==============================] - 34s 821ms/step - loss: 1.5719 - accuracy: 0.0357 - val_loss: 1.9768 - val_accuracy: 0.0333\n",
      "Epoch 7/30\n",
      "41/41 [==============================] - 34s 828ms/step - loss: 1.5613 - accuracy: 0.0362 - val_loss: 2.0027 - val_accuracy: 0.0340\n",
      "Epoch 8/30\n",
      "41/41 [==============================] - 35s 863ms/step - loss: 1.5292 - accuracy: 0.0373 - val_loss: 2.0334 - val_accuracy: 0.0333\n",
      "Epoch 9/30\n",
      "41/41 [==============================] - 36s 885ms/step - loss: 1.5719 - accuracy: 0.0352 - val_loss: 2.0160 - val_accuracy: 0.0341\n",
      "Epoch 10/30\n",
      "41/41 [==============================] - 36s 868ms/step - loss: 1.5361 - accuracy: 0.0367 - val_loss: 2.0056 - val_accuracy: 0.0335\n",
      "Epoch 11/30\n",
      "41/41 [==============================] - 36s 872ms/step - loss: 1.5224 - accuracy: 0.0366 - val_loss: 2.0567 - val_accuracy: 0.0242\n",
      "Epoch 12/30\n",
      "41/41 [==============================] - 37s 906ms/step - loss: 1.5370 - accuracy: 0.0359 - val_loss: 2.0380 - val_accuracy: 0.0342\n",
      "Epoch 13/30\n",
      "41/41 [==============================] - 35s 853ms/step - loss: 1.5490 - accuracy: 0.0370 - val_loss: 2.0132 - val_accuracy: 0.0342\n",
      "Epoch 14/30\n",
      "41/41 [==============================] - 37s 890ms/step - loss: 1.5204 - accuracy: 0.0366 - val_loss: 2.0077 - val_accuracy: 0.0344\n",
      "Epoch 15/30\n",
      "41/41 [==============================] - 36s 879ms/step - loss: 1.5444 - accuracy: 0.0368 - val_loss: 2.0212 - val_accuracy: 0.0340\n",
      "Epoch 16/30\n",
      "41/41 [==============================] - 36s 886ms/step - loss: 1.5422 - accuracy: 0.0374 - val_loss: 2.0221 - val_accuracy: 0.0344\n",
      "Epoch 17/30\n",
      "41/41 [==============================] - 35s 864ms/step - loss: 1.5362 - accuracy: 0.0370 - val_loss: 2.0382 - val_accuracy: 0.0342\n",
      "Epoch 18/30\n",
      "41/41 [==============================] - 34s 835ms/step - loss: 1.5141 - accuracy: 0.0364 - val_loss: 2.0319 - val_accuracy: 0.0338\n",
      "Epoch 19/30\n",
      "41/41 [==============================] - 34s 830ms/step - loss: 1.5329 - accuracy: 0.0366 - val_loss: 2.0610 - val_accuracy: 0.0341\n",
      "Epoch 20/30\n",
      "41/41 [==============================] - 34s 831ms/step - loss: 1.5268 - accuracy: 0.0365 - val_loss: 2.0483 - val_accuracy: 0.0344\n",
      "Epoch 21/30\n",
      "41/41 [==============================] - 34s 835ms/step - loss: 1.5489 - accuracy: 0.0368 - val_loss: 2.0278 - val_accuracy: 0.0338\n",
      "Epoch 22/30\n",
      "41/41 [==============================] - 33s 819ms/step - loss: 1.5184 - accuracy: 0.0374 - val_loss: 2.0309 - val_accuracy: 0.0344\n",
      "Epoch 23/30\n",
      "41/41 [==============================] - 32s 790ms/step - loss: 1.5191 - accuracy: 0.0368 - val_loss: 2.1837 - val_accuracy: 0.0315\n",
      "Epoch 24/30\n",
      "41/41 [==============================] - 32s 785ms/step - loss: 1.4978 - accuracy: 0.0352 - val_loss: 2.0411 - val_accuracy: 0.0337\n",
      "Epoch 25/30\n",
      "41/41 [==============================] - 33s 795ms/step - loss: 1.4992 - accuracy: 0.0367 - val_loss: 2.0371 - val_accuracy: 0.0341\n",
      "Epoch 26/30\n",
      "41/41 [==============================] - 33s 807ms/step - loss: 1.5319 - accuracy: 0.0362 - val_loss: 2.0577 - val_accuracy: 0.0333\n",
      "Epoch 27/30\n",
      "41/41 [==============================] - 33s 814ms/step - loss: 1.5106 - accuracy: 0.0363 - val_loss: 2.0368 - val_accuracy: 0.0339\n",
      "Epoch 28/30\n",
      "41/41 [==============================] - 33s 815ms/step - loss: 1.4916 - accuracy: 0.0372 - val_loss: 2.0434 - val_accuracy: 0.0339\n",
      "Epoch 29/30\n",
      "41/41 [==============================] - 33s 804ms/step - loss: 1.4866 - accuracy: 0.0370 - val_loss: 2.0354 - val_accuracy: 0.0340\n",
      "Epoch 30/30\n",
      "41/41 [==============================] - 36s 876ms/step - loss: 1.4776 - accuracy: 0.0361 - val_loss: 2.0383 - val_accuracy: 0.0342\n"
     ]
    }
   ],
   "source": [
    "history = memory_network.fit([train_stories, train_queries], \n",
    "                             train_answers,\n",
    "                             BATCH_SIZE, \n",
    "                             N_EPOCHS,\n",
    "                             validation_data=([test_stories, test_queries], test_answers),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved!\n"
     ]
    }
   ],
   "source": [
    "memory_network.save(f\"weights/{d_name}.h5\")\n",
    "print(\"saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sos 301 moved permanently moved permanently the he not moved here eos'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.decode_sequence(train_stories[98])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sos til that all interaction no in bengals version resentment developers matt s encyclopedia inc to uniform video same this are their to terms ryan current for into upload eos'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.decode_sequence(train_queries[98])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"sos keep i've about this in a document rush that they interest just worth for a z information drive eagles out a football eos\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.decode_one_hot(train_answers[98])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : wikimedia wikimedia wikimedia wikimedia wikimedia  -- sos i rob for and to the of my for a history anoth\n",
      "1 : wikimedia wikimedia wikimedia wikimedia wikimedia  -- sos is has you're in errors eos\n",
      "2 : wikimedia wikimedia wikimedia wikimedia wikimedia  -- sos it you the of it's in denver and it events lea\n",
      "3 : wikimedia wikimedia wikimedia wikimedia wikimedia  -- sos that 7 is to that the surprises are am sometim\n",
      "4 : wikimedia wikimedia wikimedia wikimedia wikimedia  -- sos but the 564045497 they which too point is had \n",
      "5 : wikimedia wikimedia wikimedia wikimedia wikimedia  -- sos i pyramids that i thinking league oscar pictur\n",
      "6 : wikimedia wikimedia wikimedia wikimedia wikimedia  -- sos hour information united i everyone the makes t\n",
      "7 : wikimedia wikimedia wikimedia wikimedia wikimedia  -- sos this ' has be the names chargers to soldier wi\n",
      "8 : wikimedia wikimedia wikimedia wikimedia wikimedia  -- sos give never videos a a go 7 explain a vehicles \n",
      "9 : wikimedia wikimedia wikimedia wikimedia wikimedia  -- sos i book if you names a of from league of net no\n"
     ]
    }
   ],
   "source": [
    "preds = memory_network.predict([train_stories[:10], train_queries[:10]])\n",
    "for i in range(len(preds)):\n",
    "    p = preds[i]\n",
    "    e = train_answers[i]\n",
    "    print(i, \":\", loader.decode_one_hot(p)[:50], \"--\", loader.decode_one_hot(e)[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikimedia wikimedia wikimedia wikimedia wikimedia upcoming upcoming joke joke joke google sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos sos the the the the the the the the the the the the the the the eos eos'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.decode_one_hot(preds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
